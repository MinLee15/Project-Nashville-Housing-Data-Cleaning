Project - Nashville Housing Data Cleaning using SQL

![Housing3a](https://user-images.githubusercontent.com/122255738/222893830-2306ee1e-49af-4802-be73-1b8cff4137d4.jpg)

Data cleaning is an essential process that involves identifying and correcting errors, inconsistencies, and inaccuracies in a dataset. It is a crucial step in the data analysis process as it helps to ensure that the insights and conclusions drawn from the data are accurate and reliable. Our project aims to achieve this by performing data cleaning on a set of housing details in Nashville using Microsoft SQL. The housing dataset in Nashville was obtained from Kaggle and contains information about various properties, including their location, size, price and etc. 

The data cleaning process involves several steps, such as :

i) Handling incorrect data types- Identify and correct these errors to ensure that the data can be properly analyzed

ii) Dealing with missing values - Missing values can occur due to various reasons such as system errors, data corruption, or human errors 

iii) Normalizing data - Help minimize data anomalies and inconsistencies, making the data more reliable and consistent

iv) Standardizing data - Data inconsistencies due to variations in spelling, capitalization, or abbreviations. Standardize the data to make it consistent and clear

v) Removing duplicate records - Duplicate records can distort the analysis results, so it's essential to remove them from the dataset

vi) Removing irrelevant data - Sometimes, a dataset might contain irrelevant data that is not necessary for the analysis. Identify and remove this data to streamline the analysis process











